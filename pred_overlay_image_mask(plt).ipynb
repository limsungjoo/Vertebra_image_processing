{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Segmentation Prediction Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_path = 'C:/Users/sungjoo/Desktop/1st_seg_mask_sample/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'C:/Users/sungjoo/Desktop/1st_seg_result_org_sample/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = 'C:/Users/sungjoo/Desktop/1st_seg_label/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "rows = 2\n",
    "cols = 5\n",
    "m=1\n",
    "    \n",
    "\n",
    "for i,j in zip(os.listdir(msk_path),os.listdir(img_path)):\n",
    "    mask = cv2.imread(os.path.join(msk_path,i), 0)\n",
    "    image = cv2.imread(os.path.join(img_path,j),0)\n",
    "    \n",
    "#     img_resized = cv2.resize(image, (512,512))\n",
    "    \n",
    "    ax1 = fig.add_subplot(rows, cols, m)\n",
    "    ax1.imshow(cv2.cvtColor(image, cv2.COLOR_BAYER_BG2GRAY), 'gray')\n",
    "    ax1.imshow(cv2.cvtColor(mask, cv2.COLOR_BAYER_BG2GRAY),alpha=0.5, cmap='Reds')\n",
    "    m+=1\n",
    "    \n",
    "plt.show()\n",
    "    \n",
    "#     plt.imshow(img_resized,'gray')\n",
    "#     plt.imshow(mask,'gray',alpha=0.3)\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "rows = 2\n",
    "cols = 5\n",
    "m=1\n",
    "    \n",
    "\n",
    "for i,j in zip(os.listdir(label_path),os.listdir(img_path)):\n",
    "    label = cv2.imread(os.path.join(label_path,i), 0)\n",
    "    image = cv2.imread(os.path.join(img_path,j),0)\n",
    "    \n",
    "#     img_resized = cv2.resize(image, (512,512))\n",
    "    \n",
    "    ax1 = fig.add_subplot(rows, cols, m)\n",
    "    ax1.imshow(cv2.cvtColor(image, cv2.COLOR_BAYER_BG2GRAY), 'gray')\n",
    "    ax1.imshow(cv2.cvtColor(label, cv2.COLOR_BAYER_BG2GRAY),alpha=0.5, cmap='Blues')\n",
    "    m+=1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure()\n",
    "plt.imshow(np.stack([img_resized] * 3, axis=-1))\n",
    "_mask = np.zeros_like(mask)\n",
    "_mask[np.where(mask == 255)] = 255\n",
    "plt.imshow(np.stack([_mask, np.zeros_like(_mask), np.zeros_like(_mask)], axis=-1), alpha=0.3)\n",
    "plt.show()\n",
    "# ax.axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Segmentation Prediction Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_img_path = 'C:/Users/sungjoo/Desktop/2nd_org'\n",
    "cropped_msk_path = 'C:/Users/sungjoo/Desktop/2nd_mask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,8))\n",
    "rows = 2\n",
    "cols = 5\n",
    "m=1\n",
    "    \n",
    "\n",
    "for i,j in zip(os.listdir(cropped_msk_path),os.listdir(cropped_img_path)):\n",
    "    mask = cv2.imread(os.path.join(cropped_msk_path,i), 0)\n",
    "    image = cv2.imread(os.path.join(cropped_img_path,j),0)\n",
    "    \n",
    "#     img_resized = cv2.resize(image, (512,512))\n",
    "    \n",
    "    ax1 = fig.add_subplot(rows, cols, m)\n",
    "    ax1.imshow(cv2.cvtColor(image, cv2.COLOR_BAYER_BG2GRAY), 'gray')\n",
    "    ax1.imshow(cv2.cvtColor(mask, cv2.COLOR_BAYER_BG2GRAY),alpha=0.3, cmap='Reds')\n",
    "    m+=1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_label_path = 'C:/Users/sungjoo/Desktop/2nd_label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizing_image_wh(image, width, height):\n",
    "    \"\"\" Applies image resizing with the size of the given length on an image and returns\n",
    "    the re-sized image with fixed size.\n",
    "    Args:\n",
    "        image (numpy.ndarray): numpy array of the image\n",
    "        height_and_width (int): length of both height and width to be re-sized\n",
    "    Returns:\n",
    "        (numpy.ndarray): numpy representation of re-sized image in size of (height_and_width, height_and_width)\n",
    "    Example:\n",
    "        > > > image = cv2.imread('1035642_.svs')\n",
    "        > > > resizing_image(image, 1024)\n",
    "        (numpy.ndarray)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not isinstance(image, np.ndarray):\n",
    "            image = np.asarray(image)\n",
    "        im = cv2.resize(image, (width, height))\n",
    "        return im\n",
    "    except Exception as error:\n",
    "        raise Exception(\"Exception occurred while resizing the image: \" + str(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_corner_points(cnts):\n",
    "    # print(\"CNTS[:]: \" + str(cnts[:]))\n",
    "    # cnts = [cnts]\n",
    "    for candi in cnts[:] :\n",
    "        print(candi.shape)\n",
    "    print([cv2.contourArea(candi) for candi in cnts[:]])\n",
    "    max_cnt = np.max([cv2.contourArea(candi) for candi in cnts[:]])\n",
    "    print(\"max_cnt: \" + str(max_cnt))\n",
    "\n",
    "    temp = []\n",
    "    for candi in cnts[:]:\n",
    "        if cv2.contourArea(candi) >= max_cnt:\n",
    "            temp.append(candi)\n",
    "    cnts = temp\n",
    "\n",
    "    rc = cv2.minAreaRect(cnts[0])\n",
    "    box = cv2.boxPoints(rc)\n",
    "    return box\n",
    "\n",
    "\n",
    "def make_empty_list_of_spine_properties(rect_list):\n",
    "    # Properties that needs to be stored in the list\n",
    "    # Index, Image array, coords, CF_Bool, Compression_ratio\n",
    "    return [['', '', '', False, 0] for (x, y, w, h) in rect_list if w*h > valid_area_threshold]\n",
    "\n",
    "\n",
    "def get_corner_points(points):\n",
    "    tuple_points = []\n",
    "    for i in range(int(len(points) / 2)):\n",
    "        tuple_points.append((points[2 * i], points[2 * i + 1]))\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sc_snd_mdl_pre_procssing(image):\n",
    "    resized_image = resizing_image_wh(image, width=256, height=768)\n",
    "    # resized_image, crop_coords = resizing_image(image, 512)\n",
    "    normalized_image = cv2.normalize(resized_image, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "    normalized_image = normalized_image * (1./255.)\n",
    "    return normalized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contour Length: 1\n",
      "(6, 4)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\imgproc\\src\\shapedescr.cpp:272: error: (-215:Assertion failed) npoints >= 0 && (depth == CV_32F || depth == CV_32S) in function 'cv::contourArea'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-98dde703df8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#         print(prep_img_2.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#         sc_2_pred = sc_2_model.predict(prep_img_2.reshape((1, 768, 256, 1))).reshape((768, 256, 1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mcropped_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc_snd_mdl_post_processing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mprep_img_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-114-f4ab6b9921a6>\u001b[0m in \u001b[0;36msc_snd_mdl_post_processing\u001b[1;34m(original_image, pred_image, original_shape)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;31m# # TODO: actual method needs to be updated after checking with LSJ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# pred_mask_binary = morphology_operation(pred_mask_binary)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[0mcropped_spine_properties\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_roi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_mask_binary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;31m#     cv2.imwrite('/data/hira2020/scoliosis/hyoon/cropped/'+name[:-4]+'_pred_msk.png', pred_mask_binary)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-114-f4ab6b9921a6>\u001b[0m in \u001b[0;36mget_roi\u001b[1;34m(original_image, mask_image)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Contour Length: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontours\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# print(\"Contour shape: \" + str(contours.shape))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_corner_points\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontours\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"box: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-131-1a1050062578>\u001b[0m in \u001b[0;36mextract_corner_points\u001b[1;34m(cnts)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcandi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcnts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontourArea\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcandi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcnts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mmax_cnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontourArea\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcandi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcnts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max_cnt: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_cnt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-131-1a1050062578>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcandi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcnts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontourArea\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcandi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcnts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mmax_cnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontourArea\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcandi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcnts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max_cnt: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_cnt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\imgproc\\src\\shapedescr.cpp:272: error: (-215:Assertion failed) npoints >= 0 && (depth == CV_32F || depth == CV_32S) in function 'cv::contourArea'\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir(cropped_label_path):\n",
    "    label= cv2.imread(os.path.join(cropped_label_path,i),0)\n",
    "    \n",
    "    prep_img_2 = sc_snd_mdl_pre_procssing(label)\n",
    "        # cv2.imwrite('/data/hira2020/scoliosis/hyoon/restored_image/' + of[:-4] + '_2nd_prep.png', prep_img_2)\n",
    "#         print(prep_img_2.shape)\n",
    "#         sc_2_pred = sc_2_model.predict(prep_img_2.reshape((1, 768, 256, 1))).reshape((768, 256, 1))\n",
    "    cropped_images = sc_snd_mdl_post_processing(label,  prep_img_2, label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roi(original_image, mask_image):\n",
    "    contour_drawn_img = original_image.copy()\n",
    "    _, contours = cv2.findContours(mask_image.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    print(\"Contour Length: \" + str(len(contours)))\n",
    "    # print(\"Contour shape: \" + str(contours.shape))\n",
    "    box = extract_corner_points(contours)\n",
    "    print(\"box: \" + str(box))\n",
    "\n",
    "    point_count = 0\n",
    "    for cnt in contours:\n",
    "        approx = cv2.approxPolyDP(cnt, 0.009*cv2.arcLength(cnt, True), True)\n",
    "        print(\"Approx DP: \" + str(approx))\n",
    "        print(\"Approx ravel: \" + str(approx.ravel()))\n",
    "        print(\"Approx ravel shape: \" + str(approx.ravel().shape))\n",
    "        print(\"Approx ravel length: \" + str(len(approx.ravel())))\n",
    "        points = approx.ravel()\n",
    "        for i in range(int(len(points)/2)):\n",
    "            print(\"point: \" + str(points[i+1]) + \", \" + str(points[i]))\n",
    "            cv2.circle(contour_drawn_img, (points[2*i], points[2*i+1]), radius, color_red, thickness)\n",
    "            point_count += 1\n",
    "        print(\"point count: \" + str(point_count))\n",
    "\n",
    "    rect = [cv2.boundingRect(cnt) for cnt in contours]\n",
    "    rect.sort(key=get_y_point)\n",
    "    spine_properties = []\n",
    "    for i, (x, y, w, h) in enumerate(rect):\n",
    "        print(\"Coord \" + str(i) + \": \" + str((x,y,w,h)))\n",
    "        print(\"Area: \" + str(w*h))\n",
    "        if w * h < valid_area_threshold:\n",
    "            continue\n",
    "\n",
    "        left, top, right, bottom = x, y, x+w, y+h\n",
    "        crop_spine = crop(original_image, (left, top, right, bottom), border=50)\n",
    "        crop_spine = cv2.cvtColor(crop_spine, cv2.COLOR_GRAY2RGB)\n",
    "        spine_properties.append([i, crop_spine, (left, top, right, bottom), False, 0])\n",
    "        # print(crop_spine.shape)\n",
    "\n",
    "        # cv2.imwrite('/data/hira2020/scoliosis/hyoon/cropped_image/'+name[:-4]+'_'+str(i)+'.png', crop_spine)\n",
    "\n",
    "        # cv2.circle(contour_drawn_img, (x, y), radius, color_red, thickness)\n",
    "        # cv2.circle(contour_drawn_img, (x+w, y), radius, color_red, thickness)\n",
    "        # cv2.circle(contour_drawn_img, (x, y+h), radius, color_red, thickness)\n",
    "        # cv2.circle(contour_drawn_img, (x+w, y+h), radius, color_red, thickness)\n",
    "#     cv2.imwrite('/data/hira2020/scoliosis/hyoon/cropped_image/' + name[:-4] + '_all_corners.png', contour_drawn_img)\n",
    "\n",
    "    return spine_properties\n",
    "\n",
    "\n",
    "def sc_snd_mdl_post_processing(original_image, pred_image, original_shape):\n",
    "    # RESTORE PRED_IMAGE to ORIGINAL IMAGE SIZE\n",
    "    pred_image = pred_image * 255\n",
    "\n",
    "    restored_pred = cv2.resize(pred_image, (original_shape[:2][::-1]))\n",
    "    # restored_pred = cv2.resize(crop(pred_image, crop_coords), (original_shape[:2][::-1]))\n",
    "\n",
    "    # cv2.imwrite('/data/hira2020/scoliosis/hyoon/cropped_image/'+name[:-4]+'_pred_msk.png', restored_pred)\n",
    "\n",
    "    # GET CROPPING POINT as the coordinate of the resized image.\n",
    "    normalized_image = cv2.normalize(restored_pred, 0, 255, norm_type=cv2.NORM_MINMAX)\n",
    "    _, pred_mask_binary = cv2.threshold(normalized_image, 128, 255, cv2.THRESH_BINARY)\n",
    "    # # TODO: actual method needs to be updated after checking with LSJ\n",
    "    # pred_mask_binary = morphology_operation(pred_mask_binary)\n",
    "    cropped_spine_properties = get_roi(original_image, pred_mask_binary)\n",
    "#     cv2.imwrite('/data/hira2020/scoliosis/hyoon/cropped/'+name[:-4]+'_pred_msk.png', pred_mask_binary)\n",
    "\n",
    "    for index, _, coord, cf_bool, cf_rate in cropped_spine_properties:\n",
    "        print(index, coord, cf_bool, cf_rate)\n",
    "\n",
    "    return cropped_spine_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
